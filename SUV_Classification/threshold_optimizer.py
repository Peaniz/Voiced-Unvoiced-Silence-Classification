import numpy as np
from typing import Dict, List, Tuple, Optional
import itertools
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from suv_classifier import SUVClassifier
from audio_analyzer import AudioAnalyzer
from evaluator import SUVEvaluator
import warnings
warnings.filterwarnings('ignore')

class ThresholdOptimizer:
    """
    T·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u cho SUV classification
    """
    
    def __init__(self):
        self.best_params = {}
        self.best_score = 0
        self.optimization_history = []
        
    def optimize_thresholds_grid_search(self, training_files: List[Tuple[str, str]], 
                                      validation_split: float = 0.5,
                                      verbose: bool = True) -> Dict:
        """
        T·ªëi ∆∞u ng∆∞·ª°ng b·∫±ng grid search v·ªõi cross-validation
        
        Args:
            training_files: List file (wav, lab)
            validation_split: T·ª∑ l·ªá chia validation
            verbose: In log hay kh√¥ng
            
        Returns:
            Dict: Best parameters t√¨m ƒë∆∞·ª£c
        """
        print("=== T·ªêI ·ª¨U NG∆Ø·ª†NG T·ª∞ ƒê·ªòNG B·∫∞NG GRID SEARCH ===\\n")
        
        # Chia train/validation
        n_train = int(len(training_files) * (1 - validation_split))
        train_files = training_files[:n_train] 
        val_files = training_files[n_train:]
        
        if len(val_files) == 0:
            val_files = train_files  # Fallback n·∫øu √≠t file
            
        print(f"Training files: {len(train_files)}")
        print(f"Validation files: {len(val_files)}\\n")
        
        # ƒê·ªãnh nghƒ©a search space
        frame_lengths = [0.020, 0.025, 0.030]  # 20ms, 25ms, 30ms
        frame_shifts = [0.008, 0.010, 0.012]   # 8ms, 10ms, 12ms  
        
        # T·ªëi ∆∞u 3 ng∆∞·ª°ng ch√≠nh theo SUVDA
        # Energy threshold factors (STE cho silence vs speech)
        energy_threshold_factors = [0.3, 0.5, 0.7, 1.0, 1.2, 1.5, 2.0]
        
        # ZCR threshold factors (ZCR cho voiced vs unvoiced)
        zcr_threshold_factors = [0.3, 0.5, 0.7, 0.8, 1.0, 1.2, 1.5]
        
        # ST threshold factors (Spectrum Tilt cho voiced vs unvoiced)
        st_threshold_factors = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]  # Xung quanh 0.7 t·ª´ b√†i b√°o
        
        best_score = 0
        best_params = {}
        iteration = 0
        total_iterations = (len(frame_lengths) * len(frame_shifts) * 
                          len(energy_threshold_factors) * len(zcr_threshold_factors) * 
                          len(st_threshold_factors))
        
        print(f"T·ªïng s·ªë combinations c·∫ßn test: {total_iterations}\\n")
        
        # Grid search
        for frame_length in frame_lengths:
            for frame_shift in frame_shifts:
                # Train classifier v·ªõi frame parameters n√†y
                classifier = SUVClassifier(frame_length=frame_length, 
                                         frame_shift=frame_shift, 
                                         sr=16000)
                
                try:
                    # Hu·∫•n luy·ªán ƒë·ªÉ l·∫•y baseline statistics
                    baseline_stats = classifier.train(train_files)
                    
                    # L·∫•y baseline thresholds (3 ng∆∞·ª°ng ch√≠nh)
                    baseline_energy_threshold = baseline_stats['ste_thresholds']['speech_silence']
                    baseline_zcr_threshold = baseline_stats['zcr_thresholds']['voiced_unvoiced']
                    baseline_st_threshold = baseline_stats['st_thresholds']['voiced_unvoiced']
                    
                    # Test different threshold combinations (3 v√≤ng l·∫∑p)
                    for energy_factor in energy_threshold_factors:
                        for zcr_factor in zcr_threshold_factors:
                            for st_factor in st_threshold_factors:
                                iteration += 1
                                
                                if iteration % 50 == 0:
                                    print(f"Progress: {iteration}/{total_iterations} ({iteration/total_iterations*100:.1f}%)")
                                
                                # Set custom thresholds (3 ng∆∞·ª°ng ch√≠nh)
                                energy_threshold = baseline_energy_threshold * energy_factor
                                zcr_threshold = baseline_zcr_threshold * zcr_factor
                                st_threshold = baseline_st_threshold * st_factor
                                
                                # Clamp ST threshold v√†o kho·∫£ng h·ª£p l√Ω
                                st_threshold = max(0.3, min(0.95, st_threshold))
                                
                                classifier.ste_thresholds['speech_silence'] = energy_threshold
                                classifier.ste_thresholds['voiced_unvoiced'] = 0  # Kh√¥ng d√πng
                                classifier.zcr_thresholds['speech_silence'] = 0   # Kh√¥ng d√πng
                                classifier.zcr_thresholds['voiced_unvoiced'] = zcr_threshold
                                classifier.st_thresholds['speech_silence'] = 0    # Kh√¥ng d√πng
                                classifier.st_thresholds['voiced_unvoiced'] = st_threshold
                                
                                # ƒê√°nh gi√° tr√™n validation set
                                score = self._evaluate_params(classifier, val_files)
                                
                                # Track history
                                params = {
                                    'frame_length': frame_length,
                                    'frame_shift': frame_shift,
                                    'energy_threshold': energy_threshold,
                                    'zcr_threshold': zcr_threshold,
                                    'st_threshold': st_threshold,
                                    # ƒê·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
                                    'ste_speech_silence': energy_threshold,
                                    'ste_voiced_unvoiced': 0,
                                    'zcr_speech_silence': 0,
                                    'zcr_voiced_unvoiced': zcr_threshold,
                                    'st_speech_silence': 0,
                                    'st_voiced_unvoiced': st_threshold,
                                    'score': score
                                }
                                
                                self.optimization_history.append(params)
                                
                                # Update best
                                if score > best_score:
                                    best_score = score
                                    best_params = params.copy()
                                    
                                    if verbose:
                                        print(f"\\nüéØ NEW BEST SCORE: {score:.4f}")
                                        print(f"   Frame: {frame_length*1000:.0f}ms/{frame_shift*1000:.0f}ms")
                                        print(f"   Energy Threshold: {energy_threshold:.6f}")
                                        print(f"   ZCR Threshold: {zcr_threshold:.6f}")
                                        print(f"   üÜï ST Threshold: {st_threshold:.6f}")
                                
                except Exception as e:
                    if verbose:
                        print(f"   Error with frame_length={frame_length}, frame_shift={frame_shift}: {e}")
                    continue
        
        self.best_params = best_params
        self.best_score = best_score
        
        print(f"\\n=== K·∫æT QU·∫¢ T·ªêI ·ª¨U ===")
        print(f"Best Score: {best_score:.4f}")
        print(f"Best Frame Length: {best_params['frame_length']*1000:.0f}ms")
        print(f"Best Frame Shift: {best_params['frame_shift']*1000:.0f}ms")
        print(f"üéØ Best Energy Threshold: {best_params['energy_threshold']:.6f}")
        print(f"üéØ Best ZCR Threshold: {best_params['zcr_threshold']:.6f}")
        print(f"üÜï Best ST Threshold: {best_params['st_threshold']:.6f}")
        
        print(f"\\nüìã Chi ti·∫øt 3 ng∆∞·ª°ng ch√≠nh (SUVDA):")
        print(f"   1. Energy Threshold (STE): T√°ch silence vs speech = {best_params['energy_threshold']:.6f}")
        print(f"   2. ZCR Threshold: T√°ch voiced vs unvoiced = {best_params['zcr_threshold']:.6f}")
        print(f"   3. üÜï Spectrum Tilt Threshold: Voiced>ST vs Unvoiced<ST = {best_params['st_threshold']:.6f}")
        
        return best_params
    
    def _evaluate_params(self, classifier: SUVClassifier, val_files: List[Tuple[str, str]]) -> float:
        """
        ƒê√°nh gi√° m·ªôt b·ªô parameters tr√™n validation set
        
        Args:
            classifier: Classifier ƒë√£ ƒë∆∞·ª£c config
            val_files: Validation files
            
        Returns:
            float: ƒêi·ªÉm ƒë√°nh gi√° (F1-weighted)
        """
        analyzer = AudioAnalyzer(classifier.analyzer.frame_length, 
                               classifier.analyzer.frame_shift, 
                               classifier.analyzer.sr)
        
        all_true_labels = []
        all_pred_labels = []
        
        try:
            for wav_path, lab_path in val_files:
                # Classify (gi·ªù c√≥ th√™m ST)
                audio, ste, zcr, st, predictions = classifier.classify(wav_path)
                smoothed_predictions = classifier.smooth_predictions(predictions, min_segment_length=30)
                
                # Ground truth
                segments = analyzer.load_labels(lab_path)
                true_labels = analyzer.get_frame_labels(segments, len(audio))
                
                # Align lengths
                min_length = min(len(true_labels), len(smoothed_predictions))
                true_labels = true_labels[:min_length]
                smoothed_predictions = smoothed_predictions[:min_length]
                
                all_true_labels.extend(true_labels)
                all_pred_labels.extend(smoothed_predictions)
            
            # T√≠nh weighted F1 score
            if len(all_true_labels) > 0:
                f1_weighted = f1_score(all_true_labels, all_pred_labels, average='weighted')
                accuracy = accuracy_score(all_true_labels, all_pred_labels)
                
                # Combined score: 70% F1 + 30% accuracy
                combined_score = 0.7 * f1_weighted + 0.3 * accuracy
                return combined_score
            else:
                return 0.0
                
        except Exception:
            return 0.0
    
    def adaptive_threshold_per_file(self, classifier: SUVClassifier, 
                                  training_files: List[Tuple[str, str]],
                                  target_file: str) -> Dict:
        """
        T√¨m ng∆∞·ª°ng adaptive cho t·ª´ng file c·ª• th·ªÉ
        
        Args:
            classifier: Base classifier
            training_files: Training data
            target_file: File c·∫ßn t·ªëi ∆∞u ng∆∞·ª°ng
            
        Returns:
            Dict: Adaptive thresholds
        """
        print(f"\\n=== ADAPTIVE THRESHOLDING CHO {target_file} ===")
        
        # Load target file ƒë·ªÉ ph√¢n t√≠ch
        analyzer = AudioAnalyzer(classifier.analyzer.frame_length,
                               classifier.analyzer.frame_shift,
                               classifier.analyzer.sr)
        
        audio, _ = analyzer.load_audio(target_file)
        ste = analyzer.compute_ste(audio)
        zcr = analyzer.compute_zcr(audio)
        
        # Ph√¢n t√≠ch ƒë·∫∑c t√≠nh c·ªßa file n√†y
        ste_stats = {
            'mean': np.mean(ste),
            'std': np.std(ste),
            'min': np.min(ste),
            'max': np.max(ste),
            'median': np.median(ste)
        }
        
        zcr_stats = {
            'mean': np.mean(zcr),
            'std': np.std(zcr),
            'min': np.min(zcr),
            'max': np.max(zcr),
            'median': np.median(zcr)
        }
        
        # T√≠nh ST cho file n√†y
        st = analyzer.compute_spectrum_tilt(audio)
        st_stats = {
            'mean': np.mean(st),
            'std': np.std(st),
            'min': np.min(st),
            'max': np.max(st),
            'median': np.median(st)
        }
        
        # Adaptive thresholds - 3 ng∆∞·ª°ng ch√≠nh
        adaptive_thresholds = {
            # Energy threshold d·ª±a tr√™n percentile c·ªßa STE
            'energy_threshold': np.percentile(ste, 20),  # 20th percentile t√°ch silence vs speech
            'zcr_threshold': zcr_stats['median'],  # Median ZCR t√°ch voiced vs unvoiced
            'st_threshold': max(0.5, min(0.85, st_stats['mean'])),  # ST threshold adaptive
            
            # ƒê·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
            'ste_speech_silence': np.percentile(ste, 20),
            'ste_voiced_unvoiced': 0,
            'zcr_speech_silence': 0,
            'zcr_voiced_unvoiced': zcr_stats['median'],
            'st_speech_silence': 0,
            'st_voiced_unvoiced': max(0.5, min(0.85, st_stats['mean']))
        }
        
        print(f"File characteristics:")
        print(f"  STE: mean={ste_stats['mean']:.4f}, std={ste_stats['std']:.4f}")
        print(f"  ZCR: mean={zcr_stats['mean']:.4f}, std={zcr_stats['std']:.4f}")
        print(f"  üÜï ST: mean={st_stats['mean']:.4f}, std={st_stats['std']:.4f}")
        
        print(f"üéØ Adaptive thresholds (3 ng∆∞·ª°ng SUVDA):")
        print(f"  Energy Threshold: {adaptive_thresholds['energy_threshold']:.6f}")
        print(f"  ZCR Threshold: {adaptive_thresholds['zcr_threshold']:.6f}")
        print(f"  üÜï ST Threshold: {adaptive_thresholds['st_threshold']:.6f}")
        
        print(f"\\nüìã Logic SUVDA √°p d·ª•ng:")
        print(f"  1. Silence: STE < {adaptive_thresholds['energy_threshold']:.4f} AND ZCR < {adaptive_thresholds['zcr_threshold']:.4f}")
        print(f"  2. Voiced: STE ‚â• {adaptive_thresholds['energy_threshold']:.4f} AND ST > {adaptive_thresholds['st_threshold']:.4f} AND ZCR < {adaptive_thresholds['zcr_threshold']:.4f}")
        print(f"  3. Unvoiced: STE ‚â• {adaptive_thresholds['energy_threshold']:.4f} AND ST < {adaptive_thresholds['st_threshold']:.4f} AND ZCR > {adaptive_thresholds['zcr_threshold']:.4f}")
        
        return adaptive_thresholds
    
    def get_optimization_report(self) -> str:
        """
        T·∫°o b√°o c√°o chi ti·∫øt v·ªÅ qu√° tr√¨nh optimization
        """
        if not self.optimization_history:
            return "Ch∆∞a c√≥ d·ªØ li·ªáu optimization"
        
        history = self.optimization_history
        
        report = "=== B√ÅO C√ÅO T·ªêI ·ª¨U NG∆Ø·ª†NG ===\\n\\n"
        
        # Top 10 best configurations
        sorted_history = sorted(history, key=lambda x: x['score'], reverse=True)
        top_10 = sorted_history[:10]
        
        report += "TOP 10 C·∫§U H√åNH T·ªêT NH·∫§T:\\n"
        report += f"{'Rank':<5} {'Score':<8} {'Frame(ms)':<10} {'Energy_Th':<10} {'ZCR_Th':<10} {'ST_Th':<10}\\n"
        report += "-" * 75 + "\\n"
        
        for i, config in enumerate(top_10):
            frame_str = f"{config['frame_length']*1000:.0f}/{config['frame_shift']*1000:.0f}"
            energy_thresh = config.get('energy_threshold', config.get('ste_speech_silence', 0))
            zcr_thresh = config.get('zcr_threshold', config.get('zcr_voiced_unvoiced', 0))
            st_thresh = config.get('st_threshold', config.get('st_voiced_unvoiced', 0.7))
            report += f"{i+1:<5} {config['score']:<8.4f} {frame_str:<10} "
            report += f"{energy_thresh:<10.4f} {zcr_thresh:<10.4f} {st_thresh:<10.4f}\\n"
        
        # Statistics
        scores = [h['score'] for h in history]
        report += f"\\nTH·ªêNG K√ä:\\n"
        report += f"T·ªïng s·ªë c·∫•u h√¨nh test: {len(history)}\\n"
        report += f"Score cao nh·∫•t: {max(scores):.4f}\\n"
        report += f"Score th·∫•p nh·∫•t: {min(scores):.4f}\\n"
        report += f"Score trung b√¨nh: {np.mean(scores):.4f}\\n"
        report += f"ƒê·ªô l·ªách chu·∫©n: {np.std(scores):.4f}\\n"
        
        return report
    
    def optimize_dynamic_thresholds(self, training_files: List[str], 
                                  verbose: bool = True) -> Dict:
        """
        T·ªëi ∆∞u DYNAMIC THRESHOLDS (kh√¥ng c·∫ßn ground truth)
        
        Args:
            training_files: List audio files (ch·ªâ .wav, kh√¥ng c·∫ßn .lab)
            verbose: In log hay kh√¥ng
            
        Returns:
            Dict: Best W parameters t√¨m ƒë∆∞·ª£c
        """
        print("=== DYNAMIC THRESHOLD OPTIMIZATION (UNSUPERVISED) ===\\n")
        print("Theo b√†i b√°o: T = (W √ó M1 + M2) / (W + 1)")
        
        # Chu·∫©n h√≥a input ƒë·ªÉ ch·ªâ l·∫•y wav files
        wav_files = []
        if len(training_files) > 0 and isinstance(training_files[0], tuple):
            wav_files = [wav_path for wav_path, _ in training_files]
        else:
            wav_files = training_files
            
        print(f"Audio files: {len(wav_files)}")
        
        # Search space cho W parameters (GI·∫¢M ƒê·ªÇ TR√ÅNH LOOP)
        W_values = [0.8, 1.0, 1.2]  # Gi·∫£m t·ª´ 5 xu·ªëng 3 values
        frame_lengths = [0.025]  # Ch·ªâ d√πng 1 frame length
        frame_shifts = [0.010]   # Ch·ªâ d√πng 1 frame shift
        
        total_combinations = len(W_values)**3 * len(frame_lengths) * len(frame_shifts)
        print(f"Search space: {total_combinations} combinations (W_STE √ó W_ZCR √ó W_ST √ó frames)")
        print("CAUTION: Reduced search space to prevent infinite loops")
        
        best_params = None
        best_separation_score = -1
        current_iteration = 0
        max_iterations = 50  # SAFETY LIMIT
        
        for frame_length in frame_lengths:
            for frame_shift in frame_shifts:
                for w_ste in W_values:
                    for w_zcr in W_values:
                        for w_st in W_values:
                            current_iteration += 1
                            
                            # SAFETY CHECK
                            if current_iteration > max_iterations:
                                print(f"SAFETY STOP: Reached max iterations ({max_iterations})")
                                break
                            
                            try:
                                print(f"\\nTesting combination {current_iteration}/{total_combinations}")
                                print(f"  Frame: {frame_length*1000:.0f}ms/{frame_shift*1000:.0f}ms")
                                print(f"  W values: STE={w_ste}, ZCR={w_zcr}, ST={w_st}")
                                
                                # Test combination
                                classifier = SUVClassifier(
                                    frame_length=frame_length,
                                    frame_shift=frame_shift,
                                    sr=16000
                                )
                                
                                # Custom training with specific W values
                                dynamic_stats = self._train_with_custom_W(
                                    classifier, wav_files, w_ste, w_zcr, w_st
                                )
                                
                                # ƒê√°nh gi√° separation quality (unsupervised metric)
                                separation_score = self._evaluate_cluster_separation(dynamic_stats)
                                print(f"  ‚Üí Separation score: {separation_score:.4f}")
                                
                                params = {
                                    'frame_length': frame_length,
                                    'frame_shift': frame_shift,
                                    'W_STE': w_ste,
                                    'W_ZCR': w_zcr,
                                    'W_ST': w_st,
                                    'separation_score': separation_score,
                                    'energy_threshold': classifier.ste_thresholds['speech_silence'],
                                    'zcr_threshold': classifier.zcr_thresholds['voiced_unvoiced'],
                                    'st_threshold': classifier.st_thresholds['voiced_unvoiced'],
                                    'ste_speech_silence': classifier.ste_thresholds['speech_silence'],
                                    'ste_voiced_unvoiced': 0,
                                    'zcr_speech_silence': 0,
                                    'zcr_voiced_unvoiced': classifier.zcr_thresholds['voiced_unvoiced'],
                                    'st_speech_silence': 0,
                                    'st_voiced_unvoiced': classifier.st_thresholds['voiced_unvoiced'],
                                    'score': separation_score
                                }
                                
                                if separation_score > best_separation_score:
                                    best_separation_score = separation_score
                                    best_params = params.copy()
                                    print(f"  ‚úÖ NEW BEST: {separation_score:.4f}")
                                    
                            except Exception as e:
                                print(f"  ‚ùå ERROR in iteration {current_iteration}: {str(e)}")
                                continue
                        
                        # NESTED LOOP SAFETY CHECK
                        if current_iteration > max_iterations:
                            break
                    if current_iteration > max_iterations:
                        break
                if current_iteration > max_iterations:
                    break
            if current_iteration > max_iterations:
                break
        
        # FALLBACK N·∫æUS KH√îNG T√åM ƒê∆Ø·ª¢C BEST PARAMS
        if best_params is None:
            print("\\n‚ö†Ô∏è  WARNING: No valid parameters found, using fallback!")
            # Train v·ªõi default W values
            fallback_classifier = SUVClassifier(frame_length=0.025, frame_shift=0.010, sr=16000)
            try:
                fallback_stats = self._train_with_custom_W(fallback_classifier, wav_files, 1.0, 1.0, 1.0)
                fallback_score = self._evaluate_cluster_separation(fallback_stats)
                best_params = {
                    'frame_length': 0.025,
                    'frame_shift': 0.010,
                    'W_STE': 1.0,
                    'W_ZCR': 1.0,
                    'W_ST': 1.0,
                    'separation_score': fallback_score,
                    'energy_threshold': fallback_classifier.ste_thresholds['speech_silence'],
                    'zcr_threshold': fallback_classifier.zcr_thresholds['voiced_unvoiced'],
                    'st_threshold': fallback_classifier.st_thresholds['voiced_unvoiced'],
                    'ste_speech_silence': fallback_classifier.ste_thresholds['speech_silence'],
                    'ste_voiced_unvoiced': 0,
                    'zcr_speech_silence': 0,
                    'zcr_voiced_unvoiced': fallback_classifier.zcr_thresholds['voiced_unvoiced'],
                    'st_speech_silence': 0,
                    'st_voiced_unvoiced': fallback_classifier.st_thresholds['voiced_unvoiced'],
                    'score': fallback_score
                }
                best_separation_score = fallback_score
            except Exception as e:
                print(f"Even fallback failed: {e}")
                return None
        
        self.best_params = best_params
        self.best_score = best_separation_score
        
        print(f"\\n=== DYNAMIC OPTIMIZATION COMPLETED ===")
        print(f"Best Separation Score: {best_separation_score:.4f}")
        print(f"Best Parameters:")
        print(f"  Frame: {best_params['frame_length']*1000:.0f}ms / {best_params['frame_shift']*1000:.0f}ms")
        print(f"  W_STE: {best_params['W_STE']}")
        print(f"  W_ZCR: {best_params['W_ZCR']}")
        print(f"  W_ST: {best_params['W_ST']}")
        print(f"  Dynamic Thresholds:")
        print(f"    T_STE = {best_params['energy_threshold']:.6f}")
        print(f"    T_ZCR = {best_params['zcr_threshold']:.6f}")
        print(f"    T_ST = {best_params['st_threshold']:.6f}")
        
        return best_params
    
    def _train_with_custom_W(self, classifier: SUVClassifier, wav_files: List[str], 
                           w_ste: float, w_zcr: float, w_st: float) -> Dict:
        """
        Train classifier v·ªõi custom W parameters cho dynamic threshold
        
        Args:
            classifier: SUVClassifier instance
            wav_files: List of audio file paths  
            w_ste, w_zcr, w_st: W parameters cho t·ª´ng feature
            
        Returns:
            Dict: Dynamic statistics
        """
        # Thu th·∫≠p features t·ª´ t·∫•t c·∫£ file
        all_ste_values = []
        all_zcr_values = []
        all_st_values = []
        
        max_files = min(len(wav_files), 4)  # GI·ªöI H·∫†N S·ªê FILE ƒê·ªÇ TR√ÅNH LOOP
        processed_files = 0
        
        for i, wav_path in enumerate(wav_files[:max_files]):
            try:
                print(f"    Processing {i+1}/{max_files}: {wav_path}")
                audio, _ = classifier.analyzer.load_audio(wav_path)
                
                # KI·ªÇM TRA AUDIO VALIDITY
                if len(audio) < 1000:
                    print(f"    Skipping {wav_path}: too short")
                    continue
                
                ste = classifier.analyzer.compute_ste(audio)
                zcr = classifier.analyzer.compute_zcr(audio)
                st = classifier.analyzer.compute_spectrum_tilt(audio)
                
                # KI·ªÇM TRA FEATURES VALIDITY
                if len(ste) > 0 and len(zcr) > 0 and len(st) > 0:
                    all_ste_values.extend(ste)
                    all_zcr_values.extend(zcr)
                    all_st_values.extend(st)
                    processed_files += 1
                    
            except Exception as e:
                print(f"    Error processing {wav_path}: {str(e)}")
                continue
        
        print(f"    Successfully processed {processed_files} files")
        
        # KI·ªÇM TRA ƒê·ª¶ D·ªÆ LI·ªÜU
        if len(all_ste_values) < 100:
            raise ValueError(f"Not enough features: only {len(all_ste_values)} frames")
        
        # T√≠nh dynamic thresholds v·ªõi custom W
        ste_array = np.array(all_ste_values)
        zcr_array = np.array(all_zcr_values)
        st_array = np.array(all_st_values)
        
        # TIMEOUT PROTECTION cho threshold computation
        try:
            ste_threshold, _ = classifier._dynamic_threshold_single_feature(ste_array, "STE", w_ste)
            zcr_threshold, _ = classifier._dynamic_threshold_single_feature(zcr_array, "ZCR", w_zcr)
            st_threshold, _ = classifier._dynamic_threshold_single_feature(st_array, "ST", w_st)
        except Exception as e:
            print(f"    Threshold computation failed: {e}")
            # FALLBACK THRESHOLDS
            ste_threshold = np.percentile(ste_array, 25)
            zcr_threshold = np.median(zcr_array)
            st_threshold = np.percentile(st_array, 60)
        
        # Set thresholds
        classifier.ste_thresholds['speech_silence'] = ste_threshold
        classifier.zcr_thresholds['voiced_unvoiced'] = zcr_threshold
        classifier.st_thresholds['voiced_unvoiced'] = max(0.3, min(0.9, st_threshold))
        classifier.trained = True
        
        return {
            'ste_stats': {'mean': np.mean(ste_array), 'std': np.std(ste_array)},
            'zcr_stats': {'mean': np.mean(zcr_array), 'std': np.std(zcr_array)},
            'st_stats': {'mean': np.mean(st_array), 'std': np.std(st_array)},
            'feature_ranges': {
                'ste_range': np.max(ste_array) - np.min(ste_array),
                'zcr_range': np.max(zcr_array) - np.min(zcr_array), 
                'st_range': np.max(st_array) - np.min(st_array)
            }
        }
    
    def _evaluate_cluster_separation(self, dynamic_stats: Dict) -> float:
        """
        ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng clustering/separation (unsupervised metric)
        
        Args:
            dynamic_stats: Statistics t·ª´ dynamic threshold computation
            
        Returns:
            float: Separation score (cao h∆°n = t·ªët h∆°n)
        """
        # S·ª≠ d·ª•ng coefficient of variation v√† range ƒë·ªÉ ƒë√°nh gi√° separation
        ste_stats = dynamic_stats['ste_stats']
        zcr_stats = dynamic_stats['zcr_stats']
        st_stats = dynamic_stats['st_stats']
        ranges = dynamic_stats['feature_ranges']
        
        # Coefficient of variation (std/mean) - cao h∆°n = ph√¢n t√°n t·ªët h∆°n
        ste_cv = ste_stats['std'] / (abs(ste_stats['mean']) + 1e-6)
        zcr_cv = zcr_stats['std'] / (abs(zcr_stats['mean']) + 1e-6)
        st_cv = st_stats['std'] / (abs(st_stats['mean']) + 1e-6)
        
        # Normalized ranges - cao h∆°n = dynamic range t·ªët h∆°n
        ste_norm_range = ranges['ste_range'] / (abs(ste_stats['mean']) + 1e-6)
        zcr_norm_range = ranges['zcr_range'] / (abs(zcr_stats['mean']) + 1e-6)
        st_norm_range = ranges['st_range'] / (abs(st_stats['mean']) + 1e-6)
        
        # Combined separation score
        cv_score = (ste_cv + zcr_cv + st_cv) / 3
        range_score = (ste_norm_range + zcr_norm_range + st_norm_range) / 3
        
        # Weighted combination
        separation_score = 0.6 * cv_score + 0.4 * range_score
        
        return separation_score
