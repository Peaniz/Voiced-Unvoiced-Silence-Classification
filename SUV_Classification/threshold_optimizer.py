import numpy as np
from typing import Dict, List, Tuple, Optional
import itertools
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from suv_classifier import SUVClassifier
from audio_analyzer import AudioAnalyzer
from evaluator import SUVEvaluator
import warnings
warnings.filterwarnings('ignore')

class ThresholdOptimizer:
    """
    T·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u cho SUV classification v·ªõi ground truth
    """
    
    def __init__(self):
        self.best_params = {}
        self.best_score = 0
        self.optimization_history = []
        
    def optimize_thresholds_grid_search(self, training_files: List[Tuple[str, str]], 
                                      validation_split: float = 0.5,
                                      verbose: bool = True) -> Dict:
        """
        T·ªëi ∆∞u ng∆∞·ª°ng b·∫±ng grid search v·ªõi cross-validation
        
        Args:
            training_files: List file (wav, lab)
            validation_split: T·ª∑ l·ªá chia validation
            verbose: In log hay kh√¥ng
            
        Returns:
            Dict: Best parameters t√¨m ƒë∆∞·ª£c
        """
        print("=== T·ªêI ·ª¨U NG∆Ø·ª†NG T·ª∞ ƒê·ªòNG B·∫∞NG GRID SEARCH ===\\n")
        
        # Chia train/validation
        n_train = int(len(training_files) * (1 - validation_split))
        train_files = training_files[:n_train] 
        val_files = training_files[n_train:]
        
        if len(val_files) == 0:
            val_files = train_files  # Fallback n·∫øu √≠t file
            
        print(f"Training files: {len(train_files)}")
        print(f"Validation files: {len(val_files)}\\n")
        
        # ƒê·ªãnh nghƒ©a search space
        frame_lengths = [0.020, 0.025, 0.030]  # 20ms, 25ms, 30ms
        frame_shifts = [0.008, 0.010, 0.012]   # 8ms, 10ms, 12ms  
        
        # T·ªëi ∆∞u 3 ng∆∞·ª°ng ch√≠nh theo SUVDA
        # Energy threshold factors (STE cho silence vs speech)
        energy_threshold_factors = [0.3, 0.5, 0.7, 1.0, 1.2, 1.5, 2.0]
        
        # ZCR threshold factors (ZCR cho voiced vs unvoiced)
        zcr_threshold_factors = [0.3, 0.5, 0.7, 0.8, 1.0, 1.2, 1.5]
        
        # ST threshold factors (Spectrum Tilt cho voiced vs unvoiced)
        st_threshold_factors = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]  # Xung quanh 0.7 t·ª´ b√†i b√°o
        
        best_score = 0
        best_params = {}
        iteration = 0
        total_iterations = (len(frame_lengths) * len(frame_shifts) * 
                          len(energy_threshold_factors) * len(zcr_threshold_factors) * 
                          len(st_threshold_factors))
        
        print(f"T·ªïng s·ªë combinations c·∫ßn test: {total_iterations}\\n")
        
        # Grid search
        for frame_length in frame_lengths:
            for frame_shift in frame_shifts:
                # Train classifier v·ªõi frame parameters n√†y
                classifier = SUVClassifier(frame_length=frame_length, 
                                         frame_shift=frame_shift, 
                                         sr=16000)
                
                try:
                    # Hu·∫•n luy·ªán ƒë·ªÉ l·∫•y baseline statistics
                    baseline_stats = classifier.train(train_files)
                    
                    # L·∫•y baseline thresholds (3 ng∆∞·ª°ng ch√≠nh)
                    baseline_energy_threshold = baseline_stats['ste_thresholds']['speech_silence']
                    baseline_zcr_threshold = baseline_stats['zcr_thresholds']['voiced_unvoiced']
                    baseline_st_threshold = baseline_stats['st_thresholds']['voiced_unvoiced']
                    
                    # Test different threshold combinations (3 v√≤ng l·∫∑p)
                    for energy_factor in energy_threshold_factors:
                        for zcr_factor in zcr_threshold_factors:
                            for st_factor in st_threshold_factors:
                                iteration += 1
                                
                                if iteration % 50 == 0:
                                    print(f"Progress: {iteration}/{total_iterations} ({iteration/total_iterations*100:.1f}%)")
                                
                                # Set custom thresholds (3 ng∆∞·ª°ng ch√≠nh)
                                energy_threshold = baseline_energy_threshold * energy_factor
                                zcr_threshold = baseline_zcr_threshold * zcr_factor
                                st_threshold = baseline_st_threshold * st_factor
                                
                                # Clamp ST threshold v√†o kho·∫£ng h·ª£p l√Ω
                                st_threshold = max(0.3, min(0.95, st_threshold))
                                
                                classifier.ste_thresholds['speech_silence'] = energy_threshold
                                classifier.ste_thresholds['voiced_unvoiced'] = 0  # Kh√¥ng d√πng
                                classifier.zcr_thresholds['speech_silence'] = 0   # Kh√¥ng d√πng
                                classifier.zcr_thresholds['voiced_unvoiced'] = zcr_threshold
                                classifier.st_thresholds['speech_silence'] = 0    # Kh√¥ng d√πng
                                classifier.st_thresholds['voiced_unvoiced'] = st_threshold
                                
                                # ƒê√°nh gi√° tr√™n validation set
                                score = self._evaluate_params(classifier, val_files)
                                
                                # Track history
                                params = {
                                    'frame_length': frame_length,
                                    'frame_shift': frame_shift,
                                    'energy_threshold': energy_threshold,
                                    'zcr_threshold': zcr_threshold,
                                    'st_threshold': st_threshold,
                                    # ƒê·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
                                    'ste_speech_silence': energy_threshold,
                                    'ste_voiced_unvoiced': 0,
                                    'zcr_speech_silence': 0,
                                    'zcr_voiced_unvoiced': zcr_threshold,
                                    'st_speech_silence': 0,
                                    'st_voiced_unvoiced': st_threshold,
                                    'score': score
                                }
                                
                                self.optimization_history.append(params)
                                
                                # Update best
                                if score > best_score:
                                    best_score = score
                                    best_params = params.copy()
                                    
                                    if verbose:
                                        print(f"\\nüéØ NEW BEST SCORE: {score:.4f}")
                                        print(f"   Frame: {frame_length*1000:.0f}ms/{frame_shift*1000:.0f}ms")
                                        print(f"   Energy Threshold: {energy_threshold:.6f}")
                                        print(f"   ZCR Threshold: {zcr_threshold:.6f}")
                                        print(f"   üÜï ST Threshold: {st_threshold:.6f}")
                                
                except Exception as e:
                    if verbose:
                        print(f"   Error with frame_length={frame_length}, frame_shift={frame_shift}: {e}")
                    continue
        
        self.best_params = best_params
        self.best_score = best_score
        
        print(f"\\n=== K·∫æT QU·∫¢ T·ªêI ·ª¨U ===")
        print(f"Best Score: {best_score:.4f}")
        print(f"Best Frame Length: {best_params['frame_length']*1000:.0f}ms")
        print(f"Best Frame Shift: {best_params['frame_shift']*1000:.0f}ms")
        print(f"üéØ Best Energy Threshold: {best_params['energy_threshold']:.6f}")
        print(f"üéØ Best ZCR Threshold: {best_params['zcr_threshold']:.6f}")
        print(f"üÜï Best ST Threshold: {best_params['st_threshold']:.6f}")
        
        print(f"\\nüìã Chi ti·∫øt 3 ng∆∞·ª°ng ch√≠nh (SUVDA):")
        print(f"   1. Energy Threshold (STE): T√°ch silence vs speech = {best_params['energy_threshold']:.6f}")
        print(f"   2. ZCR Threshold: T√°ch voiced vs unvoiced = {best_params['zcr_threshold']:.6f}")
        print(f"   3. üÜï Spectrum Tilt Threshold: Voiced>ST vs Unvoiced<ST = {best_params['st_threshold']:.6f}")
        
        return best_params
    
    def _evaluate_params(self, classifier: SUVClassifier, val_files: List[Tuple[str, str]]) -> float:
        """
        ƒê√°nh gi√° m·ªôt b·ªô parameters tr√™n validation set
        
        Args:
            classifier: Classifier ƒë√£ ƒë∆∞·ª£c config
            val_files: Validation files
            
        Returns:
            float: ƒêi·ªÉm ƒë√°nh gi√° (F1-weighted)
        """
        analyzer = AudioAnalyzer(classifier.analyzer.frame_length, 
                               classifier.analyzer.frame_shift, 
                               classifier.analyzer.sr)
        
        all_true_labels = []
        all_pred_labels = []
        
        try:
            for wav_path, lab_path in val_files:
                # Classify (gi·ªù c√≥ th√™m ST)
                audio, ste, zcr, st, predictions = classifier.classify(wav_path)
                smoothed_predictions = classifier.smooth_predictions(predictions, min_segment_length=30)
                
                # Ground truth
                segments = analyzer.load_labels(lab_path)
                true_labels = analyzer.get_frame_labels(segments, len(audio))
                
                # Align lengths
                min_length = min(len(true_labels), len(smoothed_predictions))
                true_labels = true_labels[:min_length]
                smoothed_predictions = smoothed_predictions[:min_length]
                
                all_true_labels.extend(true_labels)
                all_pred_labels.extend(smoothed_predictions)
            
            # T√≠nh weighted F1 score
            if len(all_true_labels) > 0:
                f1_weighted = f1_score(all_true_labels, all_pred_labels, average='weighted')
                accuracy = accuracy_score(all_true_labels, all_pred_labels)
                
                # Combined score: 70% F1 + 30% accuracy
                combined_score = 0.7 * f1_weighted + 0.3 * accuracy
                return combined_score
            else:
                return 0.0
                
        except Exception:
            return 0.0
    
    def adaptive_threshold_per_file(self, classifier: SUVClassifier, 
                                  training_files: List[Tuple[str, str]],
                                  target_file: str) -> Dict:
        """
        T√¨m ng∆∞·ª°ng adaptive cho t·ª´ng file c·ª• th·ªÉ
        
        Args:
            classifier: Base classifier
            training_files: Training data
            target_file: File c·∫ßn t·ªëi ∆∞u ng∆∞·ª°ng
            
        Returns:
            Dict: Adaptive thresholds
        """
        print(f"\\n=== ADAPTIVE THRESHOLDING CHO {target_file} ===")
        
        # Load target file ƒë·ªÉ ph√¢n t√≠ch
        analyzer = AudioAnalyzer(classifier.analyzer.frame_length,
                               classifier.analyzer.frame_shift,
                               classifier.analyzer.sr)
        
        audio, _ = analyzer.load_audio(target_file)
        ste = analyzer.compute_ste(audio)
        zcr = analyzer.compute_zcr(audio)
        
        # Ph√¢n t√≠ch ƒë·∫∑c t√≠nh c·ªßa file n√†y
        ste_stats = {
            'mean': np.mean(ste),
            'std': np.std(ste),
            'min': np.min(ste),
            'max': np.max(ste),
            'median': np.median(ste)
        }
        
        zcr_stats = {
            'mean': np.mean(zcr),
            'std': np.std(zcr),
            'min': np.min(zcr),
            'max': np.max(zcr),
            'median': np.median(zcr)
        }
        
        # T√≠nh ST cho file n√†y
        st = analyzer.compute_spectrum_tilt(audio)
        st_stats = {
            'mean': np.mean(st),
            'std': np.std(st),
            'min': np.min(st),
            'max': np.max(st),
            'median': np.median(st)
        }
        
        # Adaptive thresholds - 3 ng∆∞·ª°ng ch√≠nh
        adaptive_thresholds = {
            # Energy threshold d·ª±a tr√™n percentile c·ªßa STE
            'energy_threshold': np.percentile(ste, 20),  # 20th percentile t√°ch silence vs speech
            'zcr_threshold': zcr_stats['median'],  # Median ZCR t√°ch voiced vs unvoiced
            'st_threshold': max(0.5, min(0.85, st_stats['mean'])),  # ST threshold adaptive
            
            # ƒê·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
            'ste_speech_silence': np.percentile(ste, 20),
            'ste_voiced_unvoiced': 0,
            'zcr_speech_silence': 0,
            'zcr_voiced_unvoiced': zcr_stats['median'],
            'st_speech_silence': 0,
            'st_voiced_unvoiced': max(0.5, min(0.85, st_stats['mean']))
        }
        
        print(f"File characteristics:")
        print(f"  STE: mean={ste_stats['mean']:.4f}, std={ste_stats['std']:.4f}")
        print(f"  ZCR: mean={zcr_stats['mean']:.4f}, std={zcr_stats['std']:.4f}")
        print(f"  üÜï ST: mean={st_stats['mean']:.4f}, std={st_stats['std']:.4f}")
        
        print(f"üéØ Adaptive thresholds (3 ng∆∞·ª°ng SUVDA):")
        print(f"  Energy Threshold: {adaptive_thresholds['energy_threshold']:.6f}")
        print(f"  ZCR Threshold: {adaptive_thresholds['zcr_threshold']:.6f}")
        print(f"  üÜï ST Threshold: {adaptive_thresholds['st_threshold']:.6f}")
        
        print(f"\\nüìã Logic SUVDA √°p d·ª•ng:")
        print(f"  1. Silence: STE < {adaptive_thresholds['energy_threshold']:.4f} AND ZCR < {adaptive_thresholds['zcr_threshold']:.4f}")
        print(f"  2. Voiced: STE ‚â• {adaptive_thresholds['energy_threshold']:.4f} AND ST > {adaptive_thresholds['st_threshold']:.4f} AND ZCR < {adaptive_thresholds['zcr_threshold']:.4f}")
        print(f"  3. Unvoiced: STE ‚â• {adaptive_thresholds['energy_threshold']:.4f} AND ST < {adaptive_thresholds['st_threshold']:.4f} AND ZCR > {adaptive_thresholds['zcr_threshold']:.4f}")
        
        return adaptive_thresholds
    
    def get_optimization_report(self) -> str:
        """
        T·∫°o b√°o c√°o chi ti·∫øt v·ªÅ qu√° tr√¨nh optimization
        """
        if not self.optimization_history:
            return "Ch∆∞a c√≥ d·ªØ li·ªáu optimization"
        
        history = self.optimization_history
        
        report = "=== B√ÅO C√ÅO T·ªêI ·ª¨U NG∆Ø·ª†NG ===\\n\\n"
        
        # Top 10 best configurations
        sorted_history = sorted(history, key=lambda x: x['score'], reverse=True)
        top_10 = sorted_history[:10]
        
        report += "TOP 10 C·∫§U H√åNH T·ªêT NH·∫§T:\\n"
        report += f"{'Rank':<5} {'Score':<8} {'Frame(ms)':<10} {'Energy_Th':<10} {'ZCR_Th':<10} {'ST_Th':<10}\\n"
        report += "-" * 75 + "\\n"
        
        for i, config in enumerate(top_10):
            frame_str = f"{config['frame_length']*1000:.0f}/{config['frame_shift']*1000:.0f}"
            energy_thresh = config.get('energy_threshold', config.get('ste_speech_silence', 0))
            zcr_thresh = config.get('zcr_threshold', config.get('zcr_voiced_unvoiced', 0))
            st_thresh = config.get('st_threshold', config.get('st_voiced_unvoiced', 0.7))
            report += f"{i+1:<5} {config['score']:<8.4f} {frame_str:<10} "
            report += f"{energy_thresh:<10.4f} {zcr_thresh:<10.4f} {st_thresh:<10.4f}\\n"
        
        # Statistics
        scores = [h['score'] for h in history]
        report += f"\\nTH·ªêNG K√ä:\\n"
        report += f"T·ªïng s·ªë c·∫•u h√¨nh test: {len(history)}\\n"
        report += f"Score cao nh·∫•t: {max(scores):.4f}\\n"
        report += f"Score th·∫•p nh·∫•t: {min(scores):.4f}\\n"
        report += f"Score trung b√¨nh: {np.mean(scores):.4f}\\n"
        report += f"ƒê·ªô l·ªách chu·∫©n: {np.std(scores):.4f}\\n"
        
        return report
