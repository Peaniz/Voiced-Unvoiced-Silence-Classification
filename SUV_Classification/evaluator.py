#!/usr/bin/env python3
"""
MODULE ƒê√ÅNH GI√Å SUV CLASSIFICATION
X·ª≠ l√Ω demo ph√¢n lo·∫°i, t√≠nh accuracy v√† so s√°nh v·ªõi ground truth
Ch·ªâ s·ª≠ d·ª•ng c√°c h√†m t·ª± vi·∫øt v√† built-in functions c·ªßa Python/Numpy
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from audio_analyzer import AudioAnalyzer
from suv_classifier import SUVClassifier
from plotter import plot_comparison_with_ground_truth

def find_test_files_with_labels(test_dir):
    """
    T√¨m c√°c file test c√≥ c·∫£ .wav v√† .lab ƒë·ªÉ demo v·ªõi ground truth
    
    Args:
        test_dir: Th∆∞ m·ª•c ch·ª©a file test
        
    Returns:
        List[Tuple]: Danh s√°ch (wav_path, lab_path)
    """
    test_files = []
    
    if not os.path.exists(test_dir):
        return test_files
    
    # ∆Øu ti√™n c√°c file c·ªë ƒë·ªãnh
    priority_files = ['phone_F2.wav', 'phone_M2.wav', 'studio_F2.wav', 'studio_M2.wav']
    
    # T√¨m file theo th·ª© t·ª± ∆∞u ti√™n
    for filename in priority_files:
        wav_path = os.path.join(test_dir, filename)
        lab_path = wav_path.replace('.wav', '.lab')
        
        if os.path.exists(wav_path) and os.path.exists(lab_path):
            test_files.append((wav_path, lab_path))
    
    # N·∫øu ch∆∞a ƒë·ªß 4 file, t√¨m th√™m file kh√°c
    if len(test_files) < 4:
        all_wav_files = [f for f in os.listdir(test_dir) if f.endswith('.wav')]
        
        for filename in all_wav_files:
            if filename not in priority_files:  # B·ªè qua file ƒë√£ c√≥
                wav_path = os.path.join(test_dir, filename)
                lab_path = wav_path.replace('.wav', '.lab')
                
                if os.path.exists(lab_path):
                    test_files.append((wav_path, lab_path))
                    
                if len(test_files) >= 4:
                    break
    
    return test_files[:4]  # Ch·ªâ l·∫•y t·ªëi ƒëa 4 file


def demo_classification_with_ground_truth(test_files, thresholds, results_dir):
    """
    Demo ph√¢n lo·∫°i v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u v√† so s√°nh v·ªõi ground truth
    
    Args:
        test_files: Danh s√°ch file test
        thresholds: Ng∆∞·ª°ng t·ªëi ∆∞u
        results_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    """
    print("B·∫Øt ƒë·∫ßu demo ph√¢n lo·∫°i v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u...")
    
    # Kh·ªüi t·∫°o classifier v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u
    classifier = SUVClassifier(
        frame_length=thresholds['frame_length'],
        frame_shift=thresholds['frame_shift'],
        sr=16000
    )
    
    # Set ng∆∞·ª°ng t·ªëi ∆∞u
    classifier.set_thresholds(
        ste_threshold=thresholds['ste_threshold'],
        zcr_threshold=thresholds['zcr_threshold'],
        st_threshold=thresholds['st_threshold']
    )
    
    # Kh·ªüi t·∫°o evaluator
    analyzer = AudioAnalyzer(
        frame_length=thresholds['frame_length'],
        frame_shift=thresholds['frame_shift'],
        sr=16000
    )
    
    # X·ª≠ l√Ω t·ª´ng file test v·ªõi ground truth
    for i, (wav_path, lab_path) in enumerate(test_files):
        filename = os.path.basename(wav_path)
        print(f"\nX·ª≠ l√Ω file {i+1}/{len(test_files)}: {filename}")
        
        try:
            # Ph√¢n lo·∫°i v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u
            audio, ste, zcr, st, predictions = classifier.classify(wav_path)
            
            # L√†m m·ªãn d·ª± ƒëo√°n
            smoothed_predictions = classifier.smooth_predictions(predictions, min_segment_length=30)
            
            # Load ground truth t·ª´ file .lab
            print(f"  S·ª≠ d·ª•ng ground truth: {os.path.basename(lab_path)}")
            
            segments = analyzer.load_labels(lab_path)
            true_labels = analyzer.get_frame_labels(segments, len(audio))
            
            # ƒê·∫£m b·∫£o chi·ªÅu d√†i kh·ªõp nhau
            min_length = min(len(true_labels), len(smoothed_predictions))
            true_labels = true_labels[:min_length]
            smoothed_predictions = smoothed_predictions[:min_length]
            
            # T√≠nh ƒë·ªô ch√≠nh x√°c
            accuracy = compute_accuracy_manual(true_labels, smoothed_predictions)
            print(f"  ƒê·ªô ch√≠nh x√°c: {accuracy:.4f}")
            
            # T√≠nh accuracy cho t·ª´ng class
            class_accuracies = compute_class_accuracies(true_labels, smoothed_predictions)
            print(f"  Silence Acc: {class_accuracies[0]:.4f}, Voiced Acc: {class_accuracies[1]:.4f}, Unvoiced Acc: {class_accuracies[2]:.4f}")
            
            # V·∫Ω v√† so s√°nh v·ªõi ground truth
            plot_comparison_with_ground_truth(
                audio=audio,
                ste=ste,
                zcr=zcr,
                st=st,
                predictions=predictions,
                smoothed_predictions=smoothed_predictions,
                true_labels=true_labels,
                filename=filename,
                thresholds=thresholds,
                figure_position=i,
                results_dir=results_dir
            )
            
        except Exception as e:
            print(f"  ‚úó L·ªói x·ª≠ l√Ω {filename}: {e}")
    
    print("\nüéØ Demo ph√¢n lo·∫°i v·ªõi ground truth ho√†n th√†nh!")
    plt.show()  # Hi·ªÉn th·ªã t·∫•t c·∫£ figure


def compute_accuracy_manual(y_true, y_pred):
    """
    T√≠nh accuracy th·ªß c√¥ng thay th·∫ø sklearn
    
    Args:
        y_true: Nh√£n th·ª±c
        y_pred: Nh√£n d·ª± ƒëo√°n
        
    Returns:
        float: Accuracy
    """
    if len(y_true) != len(y_pred) or len(y_true) == 0:
        return 0.0
    
    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)
    return correct / len(y_true)


def compute_class_accuracies(y_true, y_pred):
    """
    T√≠nh accuracy cho t·ª´ng class
    
    Args:
        y_true: Nh√£n th·ª±c
        y_pred: Nh√£n d·ª± ƒëo√°n
        
    Returns:
        List[float]: Accuracy cho t·ª´ng class [silence, voiced, unvoiced]
    """
    class_accuracies = []
    
    for class_id in [0, 1, 2]:  # silence, voiced, unvoiced
        mask = [true == class_id for true in y_true]
        if sum(mask) > 0:
            correct = sum(1 for i, (true, pred) in enumerate(zip(y_true, y_pred)) 
                         if mask[i] and true == pred)
            accuracy = correct / sum(mask)
        else:
            accuracy = 0.0
        class_accuracies.append(accuracy)
    
    return class_accuracies


def compute_f1_scores(y_true, y_pred):
    """
    T√≠nh F1 score cho t·ª´ng class
    
    Args:
        y_true: Nh√£n th·ª±c
        y_pred: Nh√£n d·ª± ƒëo√°n
        
    Returns:
        Dict: F1 scores cho t·ª´ng class
    """
    classes = [0, 1, 2]  # Silence, Voiced, Unvoiced
    class_names = ['Silence', 'Voiced', 'Unvoiced']
    
    f1_scores = {}
    
    for cls, name in zip(classes, class_names):
        # True Positive: D·ª± ƒëo√°n ƒë√∫ng class n√†y
        tp = sum(1 for true, pred in zip(y_true, y_pred) if true == cls and pred == cls)
        
        # False Positive: D·ª± ƒëo√°n nh·∫ßm l√† class n√†y
        fp = sum(1 for true, pred in zip(y_true, y_pred) if true != cls and pred == cls)
        
        # False Negative: B·ªè s√≥t class n√†y
        fn = sum(1 for true, pred in zip(y_true, y_pred) if true != cls and pred != cls)
        
        # Precision v√† Recall
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        # F1 score
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        f1_scores[name] = f1
    
    return f1_scores


def evaluate_single_file(classifier, wav_path, lab_path=None):
    """
    ƒê√°nh gi√° m·ªôt file duy nh·∫•t
    
    Args:
        classifier: SUVClassifier instance
        wav_path: ƒê∆∞·ªùng d·∫´n file audio
        lab_path: ƒê∆∞·ªùng d·∫´n file label (optional)
        
    Returns:
        Dict: K·∫øt qu·∫£ ƒë√°nh gi√°
    """
    # Ph√¢n lo·∫°i
    audio, ste, zcr, st, predictions = classifier.classify(wav_path)
    smoothed_predictions = classifier.smooth_predictions(predictions, min_segment_length=30)
    
    result = {
        'filename': os.path.basename(wav_path),
        'total_frames': len(predictions),
        'predictions': predictions,
        'smoothed_predictions': smoothed_predictions,
        'features': {
            'ste': ste,
            'zcr': zcr,
            'st': st
        }
    }
    
    # N·∫øu c√≥ ground truth
    if lab_path and os.path.exists(lab_path):
        analyzer = AudioAnalyzer(
            frame_length=classifier.analyzer.frame_length,
            frame_shift=classifier.analyzer.frame_shift,
            sr=classifier.analyzer.sr
        )
        
        segments = analyzer.load_labels(lab_path)
        true_labels = analyzer.get_frame_labels(segments, len(audio))
        
        # ƒê·∫£m b·∫£o chi·ªÅu d√†i kh·ªõp nhau
        min_length = min(len(true_labels), len(smoothed_predictions))
        true_labels = true_labels[:min_length]
        smoothed_predictions = smoothed_predictions[:min_length]
        
        # T√≠nh c√°c metric
        accuracy = compute_accuracy_manual(true_labels, smoothed_predictions)
        class_accuracies = compute_class_accuracies(true_labels, smoothed_predictions)
        f1_scores = compute_f1_scores(true_labels, smoothed_predictions)
        
        result.update({
            'has_ground_truth': True,
            'true_labels': true_labels,
            'accuracy': accuracy,
            'class_accuracies': {
                'silence': class_accuracies[0],
                'voiced': class_accuracies[1],
                'unvoiced': class_accuracies[2]
            },
            'f1_scores': f1_scores
        })
    else:
        result['has_ground_truth'] = False
    
    return result


def save_evaluation_results(results, results_dir):
    """
    L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° v√†o file
    
    Args:
        results: List c√°c k·∫øt qu·∫£ ƒë√°nh gi√°
        results_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    """
    report_file = os.path.join(results_dir, "evaluation_report.txt")
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=== B√ÅO C√ÅO ƒê√ÅNH GI√Å SUV CLASSIFICATION ===\n\n")
        
        total_accuracy = 0
        total_files = 0
        
        for result in results:
            f.write(f"FILE: {result['filename']}\n")
            f.write(f"T·ªïng s·ªë frames: {result['total_frames']}\n")
            
            if result['has_ground_truth']:
                f.write(f"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {result['accuracy']:.4f}\n")
                f.write(f"Accuracy theo class:\n")
                f.write(f"  - Silence: {result['class_accuracies']['silence']:.4f}\n")
                f.write(f"  - Voiced: {result['class_accuracies']['voiced']:.4f}\n")
                f.write(f"  - Unvoiced: {result['class_accuracies']['unvoiced']:.4f}\n")
                f.write(f"F1 scores:\n")
                for class_name, f1 in result['f1_scores'].items():
                    f.write(f"  - {class_name}: {f1:.4f}\n")
                
                total_accuracy += result['accuracy']
                total_files += 1
            else:
                f.write("Kh√¥ng c√≥ ground truth ƒë·ªÉ ƒë√°nh gi√°\n")
            
            f.write("\n" + "-"*50 + "\n")
        
        if total_files > 0:
            f.write(f"\nT√ìM T·∫ÆT:\n")
            f.write(f"ƒê·ªô ch√≠nh x√°c trung b√¨nh: {total_accuracy/total_files:.4f}\n")
            f.write(f"S·ªë file c√≥ ground truth: {total_files}\n")
    
    print(f"ƒê√£ l∆∞u b√°o c√°o ƒë√°nh gi√°: {report_file}")
